{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c321e3ba-e4b0-4fc5-bf31-3f29cac1114a",
   "metadata": {},
   "source": [
    "#### Open Notebook in Colab\n",
    "To open the notebook in Google Colab, click the link below:\n",
    "[Open in Colab](https://colab.research.google.com/github/JunetaeKim/GCSP-HBDA/blob/main/Week2/Lecture1.2.ipynb)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1806ba29-eec4-483d-a2fb-a2ab0b7133b2",
   "metadata": {},
   "source": [
    "### Topic: Processing and Merging TCGA Data\n",
    "##### Goals: Processing and merging TCGA (The Cancer Genome Atlas) data. \n",
    "##### We'll practice through each step, from importing necessary libraries to saving the final merged dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f90d409-4031-4c76-afd9-e649718f7ec8",
   "metadata": {},
   "source": [
    "<img src=\"https://github.com/JunetaeKim/GCSP-HBDA/raw/main/Week2/figure1.2.1.png\" alt=\"Image\" width=\"600\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfa7bbfe-0087-47bb-b55f-aa78801a5262",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "b10bd4cc-1b33-4ae2-b73c-7ab4fd273e56",
   "metadata": {},
   "source": [
    "#### 1. Importing Libraries ðŸ“š\n",
    "##### Objective: Load the necessary Python libraries for data processing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b9896ee-cf11-46ba-adb2-59710fcacd9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd  # Essential for data manipulation and analysis\n",
    "import numpy as np  # Useful for numerical operations\n",
    "import requests  # Allows us to make HTTP requests to download data\n",
    "import os  # Helps in interacting with the operating system\n",
    "import warnings  # Manages warning messages\n",
    "import sys  # Provides system-specific parameters and functions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e0c3e17-fc30-46dd-b5e1-bb5c536d2f08",
   "metadata": {},
   "source": [
    "#### Explanation: \n",
    "##### We start by importing several libraries. \n",
    "##### pandas and numpy are key for data manipulation. \n",
    "##### requests helps in downloading data files from the internet. \n",
    "##### os is used for file and directory operations, while warnings and sys are for handling system and warning messages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76093331-ac59-4144-9303-af6473823a72",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "afb33c8a-0ba1-4d55-be7b-26e3688a7846",
   "metadata": {},
   "source": [
    "#### 2. Setting File Paths ðŸ“\n",
    "#### Objective: Define where our data files will be stored and ensure necessary directories exist."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ea1c9d7-884f-4a57-8fa4-807aa0b4e1ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specify relative paths.\n",
    "FILE_DIR = './'\n",
    "DATA_DIR = os.path.join(FILE_DIR, \"SourceData\")\n",
    "RSUBREAD_FOLDER = os.path.join(FILE_DIR, \"SourceData\", \"rsubread\")\n",
    "\n",
    "# Create directories if they do not exist.\n",
    "if not os.path.exists(RSUBREAD_FOLDER):\n",
    "    os.makedirs(RSUBREAD_FOLDER)\n",
    "\n",
    "# Specify paths for the data files.\n",
    "clinical_variables_path = os.path.join(RSUBREAD_FOLDER, \"clinical_variables.txt.gz\")\n",
    "cancer_type_path = os.path.join(RSUBREAD_FOLDER, \"cancer_types.txt.gz\")\n",
    "rsubread_gene_counts_path = os.path.join(RSUBREAD_FOLDER, \"gene_counts.txt.gz\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9e034f4-b74b-4ae3-a733-74ebbb2ac3aa",
   "metadata": {},
   "source": [
    "#### Explanation: \n",
    "##### Here, we set up the file paths.\n",
    "##### os.path.join helps in creating platform-independent paths. \n",
    "##### We also check if the RSUBREAD_FOLDER directory exists, and if not, we create it to ensure our data has a place to be stored."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f4f220f-e5fd-45e1-980e-63187445dfdb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "03138539-107a-4fe5-98bd-e3f09aae8d83",
   "metadata": {},
   "source": [
    "#### 3. Downloading Data ðŸ’¾\n",
    "##### Objective: Download the necessary data files if they are not already present."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e808d996-884e-4a38-8ec2-445cd9c23221",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"____ Downloading data ____ \\n\")\n",
    "\n",
    "# Clinical Variables\n",
    "if not os.path.exists(clinical_variables_path):\n",
    "    print(\"Started Download of Clinical Variables...\")\n",
    "    clinical_variables_url = r\"https://ftp.ncbi.nlm.nih.gov/geo/series/GSE62nnn/GSE62944/suppl/GSE62944%5F06%5F01%5F15%5FTCGA%5F24%5F548%5FClinical%5FVariables%5F9264%5FSamples%2Etxt%2Egz\"\n",
    "    r = requests.get(clinical_variables_url)\n",
    "    with open(clinical_variables_path, \"wb\") as f:\n",
    "        f.write(r.content)\n",
    "    print(\"Done.\")\n",
    "else:\n",
    "    print(\"Raw data exists. Skipping Download.\")\n",
    "\n",
    "# Cancer Types\n",
    "if not os.path.exists(cancer_type_path):\n",
    "    print(\"Started Download of Cancer Types...\")\n",
    "    cancer_type_url = r\"https://ftp.ncbi.nlm.nih.gov/geo/series/GSE62nnn/GSE62944/suppl/GSE62944%5F06%5F01%5F15%5FTCGA%5F24%5FCancerType%5FSamples%2Etxt%2Egz\"\n",
    "    r = requests.get(cancer_type_url)\n",
    "    with open(cancer_type_path, \"wb\") as f:\n",
    "        f.write(r.content)\n",
    "    print(\"Done.\")\n",
    "\n",
    "# Gene Counts\n",
    "if not os.path.exists(rsubread_gene_counts_path):\n",
    "    print(\"Started Download of Gene Counts...\")\n",
    "    rsubread_gene_counts_url = r\"https://ftp.ncbi.nlm.nih.gov/geo/samples/GSM1536nnn/GSM1536837/suppl/GSM1536837%5F06%5F01%5F15%5FTCGA%5F24%2Etumor%5FRsubread%5FFeatureCounts%2Etxt%2Egz\"\n",
    "    r = requests.get(rsubread_gene_counts_url)\n",
    "    with open(rsubread_gene_counts_path, \"wb\") as f:\n",
    "        f.write(r.content)\n",
    "    print(\"Done.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93515023-594d-435f-b08b-973c7b044fc3",
   "metadata": {},
   "source": [
    "#### Explanation: \n",
    "##### In this step, we download the clinical variables, cancer types, and gene counts data if they are not already present in the specified paths. \n",
    "##### The requests.get method fetches the data from the provided URLs, and the content is written to the respective file paths.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa3cd8b7-a2b5-433c-a2bb-db0c9276041c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "f10244ed-e75f-4006-a74a-a4f21edc8bf0",
   "metadata": {},
   "source": [
    "#### 4. Reading Data ðŸ“„\n",
    "##### Objective: Load the downloaded data into pandas DataFrames for further processing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "705ab6ab-184b-4ceb-9c0c-c5924ae14bc0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(\"Opening downloaded data...\")\n",
    "\n",
    "clinical_variables = pd.read_csv(clinical_variables_path, sep=\"\\t\", compression=\"gzip\")\n",
    "cancer_types = pd.read_csv(cancer_type_path, sep=\"\\t\", header=0, names=[\"patient_id\", \"tumor_type\"], compression=\"gzip\")\n",
    "gene_counts = pd.read_csv(rsubread_gene_counts_path, sep=\"\\t\", compression=\"gzip\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "170dab69-6180-4458-a64f-58639c7ae7d1",
   "metadata": {},
   "source": [
    "#### Explanation: \n",
    "##### We use pd.read_csv to read the gzipped data files into pandas DataFrames. \n",
    "##### This step makes it easy to manipulate and analyze the data in subsequent steps."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07bbf5e3-0baf-4e61-9d0d-4b99ff097d8e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "0d91249c-aac0-4c15-a259-d1397bce559c",
   "metadata": {},
   "source": [
    "#### 5. Data Preprocessing and Merging ðŸ”„\n",
    "##### 5.1 Processing Clinical Variables ðŸ©º\n",
    "##### Objective: Clean and preprocess the clinical variables data.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8406855-e781-44b1-a0f2-a7bc71a3405a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop unnecessary columns and set index\n",
    "clinical_variables = clinical_variables.drop(columns=[\"Unnamed: 1\", \"Unnamed: 2\"])\n",
    "clinical_variables.set_index(\"Unnamed: 0\", inplace=True)\n",
    "\n",
    "# Select necessary columns\n",
    "clinical_variables = clinical_variables.loc[[\"vital_status\", \"last_contact_days_to\", \"death_days_to\", 'gender', 'birth_days_to', 'race'], :]\n",
    "clinical_variables = clinical_variables.T\n",
    "\n",
    "# Drop rows with missing values in specific columns\n",
    "clinical_variables = clinical_variables.dropna(subset=[\"vital_status\"])\n",
    "clinical_variables = clinical_variables.dropna(subset=[\"last_contact_days_to\", \"death_days_to\", \"race\"])\n",
    "\n",
    "# Filter out invalid data\n",
    "clinical_variables = clinical_variables.loc[clinical_variables.vital_status != \"[Not Available]\", :]\n",
    "clinical_variables = clinical_variables.loc[(clinical_variables.birth_days_to != \"[Not Available]\") & (clinical_variables.birth_days_to != '[Completed]'), :]\n",
    "clinical_variables = clinical_variables.loc[clinical_variables.gender != \"[Not Available]\", :]\n",
    "\n",
    "# Filter specific races\n",
    "races_to_keep = [\n",
    "    'AMERICAN INDIAN OR ALASKA NATIVE',\n",
    "    'ASIAN',\n",
    "    'BLACK OR AFRICAN AMERICAN',\n",
    "    'NATIVE HAWAIIAN OR OTHER PACIFIC ISLANDER',\n",
    "    'WHITE'\n",
    "]\n",
    "clinical_variables = clinical_variables[clinical_variables['race'].isin(races_to_keep)]\n",
    "\n",
    "# Convert birth days to age and gender to binary\n",
    "clinical_variables['birth_days_to'] = clinical_variables['birth_days_to'].astype('float32') * -1 / 365.\n",
    "clinical_variables['gender'] = pd.get_dummies(clinical_variables['gender'])['MALE']\n",
    "\n",
    "# Calculate survival time\n",
    "clinical_variables[\"time\"] = -1\n",
    "mask = clinical_variables.vital_status == \"Dead\"\n",
    "clinical_variables.time.loc[mask] = clinical_variables.death_days_to.loc[mask]\n",
    "mask = clinical_variables.vital_status == \"Alive\"\n",
    "clinical_variables.time.loc[mask] = clinical_variables.last_contact_days_to.loc[mask]\n",
    "\n",
    "# Filter usable data points\n",
    "mask = (clinical_variables.time != \"[Not Available]\") & (clinical_variables.time != \"[Discrepancy]\") & (clinical_variables.time != \"[Completed]\")\n",
    "clinical_variables = clinical_variables.loc[mask]\n",
    "\n",
    "# Convert time to numeric and filter non-positive values\n",
    "clinical_variables.time = pd.to_numeric(clinical_variables.time)\n",
    "clinical_variables = clinical_variables.loc[clinical_variables.time > 0]\n",
    "\n",
    "# Set event indicator\n",
    "clinical_variables[\"event\"] = -1\n",
    "clinical_variables.event[clinical_variables.vital_status == \"Dead\"] = True\n",
    "clinical_variables.event[clinical_variables.vital_status == \"Alive\"] = False\n",
    "\n",
    "# Select and rename columns\n",
    "clinical_variables = clinical_variables.loc[:, [\"time\", \"event\", 'gender', 'birth_days_to', 'race']]\n",
    "clinical_variables.reset_index(inplace=True)\n",
    "clinical_variables.rename(columns={\"index\": \"patient_id\", 'birth_days_to': 'age'}, inplace=True)\n",
    "\n",
    "print(\"Done.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23e6717a-6d7f-477c-b00e-5843c20a3b2f",
   "metadata": {},
   "source": [
    "#### Explanation: This section involves extensive data cleaning:\n",
    "\n",
    "##### 1.Dropping unnecessary columns and rows with missing values to ensure we only work with relevant and complete data.\n",
    "##### 2.Filtering data based on specific criteria such as valid values and certain races.\n",
    "##### 3.Transforming data by converting birth days to age and encoding gender as binary.\n",
    "##### 4.Calculating survival time and setting event indicators for further analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6fa12e9-bd3d-4e56-91cb-2bede13d6454",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "43039e10-4d39-4108-b712-ad28d13d1adb",
   "metadata": {},
   "source": [
    "##### 5.2 Merging Data ðŸ”—\n",
    "##### Objective: Combine the clinical variables, cancer types, and gene counts into a single dataset.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d35451d-a125-4cda-8720-49ea7632f5f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Merging with cancer types.\")\n",
    "patients = pd.merge(cancer_types, clinical_variables, on=[\"patient_id\"])\n",
    "print(\"Done.\")\n",
    "\n",
    "print(\"Merging with gene counts.\")\n",
    "gene_counts.set_index(\"Unnamed: 0\", inplace=True)\n",
    "gene_counts = gene_counts.T\n",
    "gene_counts.reset_index(inplace=True)\n",
    "gene_counts.rename(columns={\"index\": \"patient_id\"}, inplace=True)\n",
    "print(\"Done.\")\n",
    "\n",
    "print(\"Merging all together.\")\n",
    "full_data = pd.merge(patients, gene_counts, on=[\"patient_id\"])\n",
    "print(\"Done.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37b73af0-1134-46ac-b873-b84c2ae5f52f",
   "metadata": {},
   "source": [
    "#### Explanation: \n",
    "##### This part involves merging different datasets:\n",
    "##### 1.Merging clinical variables with cancer types to create a combined patient dataset.\n",
    "##### 2.Preparing and merging gene counts by setting the appropriate index and ensuring the patient ID is included.\n",
    "##### 3.Creating a final merged dataset that includes all relevant data for each patient."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43aaa8e6-b717-48e7-8d6b-d3fa90b36e4c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "579aedb3-fabe-42d0-8e69-056bd75b081d",
   "metadata": {},
   "source": [
    "#### 6. Saving the Merged Data ðŸ’¾\n",
    "##### Objective: Save the final merged dataset for future use."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "942e4858-9977-44be-b1f9-f90417fa1a00",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Saving merged data...\")\n",
    "full_data.to_pickle(os.path.join(RSUBREAD_FOLDER, \"complete_data_merged.pickle\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b43720f3-5460-4f14-bf0b-2877789c83ff",
   "metadata": {},
   "source": [
    "#### Explanation: \n",
    "##### Finally, we save the merged dataset to a file using the pickle format. \n",
    "##### This allows us to easily load and reuse the data later without having to repeat the preprocessing steps."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
